\chapter{IBM BigFix on SaaS, l'implementazione del prototipo}
L'attenta progettazione giudata dall'architect che abbiamo visto nel capitolo precedente è servita da base per la vera ralizzazione del prototipo che rappresenta l'aspetto implementativo del progetto BigFix SaaS. Ma queste due fasi del lavoro che stiamo presetando non sono l'una successiva l'altra. Infatti è bene rimarcare che, sguendo un approccio agile, iterativo e incrementale, l'intero disegno del progetto si è ottenuto solamente a fronte di una continua esplorazione dei requisiti che si è protratta durante tutta la fase implementativa. Il metronomo dello sviluppo sono state infatti le sprint demo, le quali vedevano la partecipazione anche di altri stackeholders interni all'azienda, oltre che al team stesso. Da questi confronti sono risultati continui feedback che hanno contribuito a portare il lavoro nel suo stato attuale.

\section{Container e microservizi di BigFix}
Per la necessità di continui feedback già dalla prima fase del progetto si è scelto di adottare, per i primi sprint, una soluzione intermedia per quanto riguarda la scomposizione del prodotto nei container. Si deciso infatti di fare in modo che, all'inizio, ogni container ospitasse un realay o un server di uno dei clienti forniti dal SaaS, e non un microservizio vero e proprio del prodotto. Questa scelta è avvenuta dopo un analisi dei requisiti. Scomporre BigFix in microservizi è un'operazione che richiede molte ore uomo di lavoro e affrontarla all'inizio del progetto non avrebbe consentito ti testare nelle primissime fasi le tecnologie che si erano individuate per il deployment. Avendo presto a disposizione gli ambienti cliente con relay e server, si sono subito testati scenari tipici del prodotto on premises nelle nuove tecnologie SaaS adottate.

\section{Gli ambienti di sviluppo }
La realizzazione di un progetto aziendale richiede più ambienti nei quali, sequenzialmente, viene testato il prodotto prima di metterlo sul mercato. L'ambiente ufficiale, quello di produzione, deve garantire tutti i parametri qualitativi di cui abbiamo parlato precedentemente. Per questo motivo è lì che si concentrano i maggiori investimenti a livello hardware per garantire alte prestazioni al servizio. Al tempo stesso però occorre avere a disposizione un "laboratorio" in cui sviluppare e testare il software, in cui implementare le nuove features quando il prodotto sarà già sul mercato, un ambiente nel quale le modifiche che si compiono al codice non impattino in nessun modo il servizio offerto ai clienti. Per questo motivo il primo contesto in cui si è andato a lavorare è l'ambiente di sviluppo. Un ambiente chiuso all'esterno dell'azienda, ma che al tempo stesso simulasse nella maniera più fedele possibile l'ambiente di produzione. A questi due si aggiunge un'ambiente intermedio di pre production, nel quale vengono svolti tutti i test qualitativi per verificare che il prodotto sia conforme ai parametri non funzionali stabiliti. 
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth,keepaspectratio=true]{capitoli/imgs/ambientisviluppo.png}
	\caption{Ambienti di BigFix SaaS}
\end{figure}

\section{Costruzione dell'ambiente e installazione di Docker e Kubernetes}
Vediamo una schematizzazione dell'ambiente di sviluppo nella figura \ref{ambs}. Kubernetes è il tool che muove le danze avendo proprio la funzione di orchestratore dei container. L'architettura di Kubernetes richiede che ci sia un nodo master che coordina i nodi denominati kube-node, che possono rappresentare macchine diverse. Su tutti i kube-node è installato anche docker, in quanto ci permetterà di ospitare su di essi i container. Questi vengono deployati su tutti i nodi a disposizione seguendo l'algoritmo di scheduling round-robin in modo da gestire al meglio le risorse di calcolo. 
\paragraph{}
Il Kubernetes master si interfaccia, come posiamo vedere, anche con altre due macchine presenti nella rete: La macchina DB2 e la macchina NFS. Andiamo a vedere di cosa si tratta.
\paragraph{DB2}
E' la macchina che ospita una replica del database. Spiegheremo in seguito come, nel processo di onboarding di un nuovo cliente, vengono dinamicamente allocate le risorse del database al nuovo utente. Le modalità di interazione tra i componenti BigFix nei container e il database ricalcano quelle del prodotto on premise.
\paragraph{Network File System (NFS)}
Questo componente è pensato per fornire storage per i container tramite protocollo NFS. L'NFS è un protocollo di rete sviluppato dalla Sun negli anni 80. Esso rappresenta un file system distribuito che consente ai computer di utilizzare la rete per accedere ai dischi rigidi remoti come fossero dischi locali. La componente NFS è stata utilizzata solamente in una prima fase del progetto in quanto, con il passaggio all'ambiente ufficiale, si è fatto affidamento allo storage fornito da un particolare componente di Kubernetes, il service. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth,keepaspectratio=true]{capitoli/imgs/EnvironmentsComponentDiagram.png}
	\caption{L'ambiente di sviluppo di BigFix SaaS}
	\label{ambs}
\end{figure}


\section{Re-working degli installer del server e del relay di BigFix}
Il server e il relay di BigFix hanno i loro tradizionali installer relativi alla versione on premise del prodotto. Ovviamente è stato necessario un grosso lavoro di re-working di questi componenti per fare in modo che risultassero molto più leggeri e adatti al deployment in un container.

\section{Le immagini Docker}
Docker consente di deployare i container partendo da immagini di una repository fornita da Docker stesso. Nel nostro caso si è scelto di porre come base di tutti i container del servizio una macchina Linux CentOS 7 sia per i relay che per i server, una scelta dettata da esigenze aziendali. Docker fornisce delle versioni a container di molti sistemi operativi in modo da personalizzare secondo le proprie esigenze i container che si vanno ad implementare.

\paragraph{}
Questa macchina CentOS è ovviamente una versione molto embrionale dei servizi necessari per il prodotto. E' stato necessario creare delle directory di BigFix apposite per ospitare l'installer del server o del relay, a seconda dei casi. Si sono poste poi, all'interno di opportune cartelle, due file bash fondamentali per il deployment: install.sh e start.sh. Nella prossima sezione spieghiamo il loro compito.

\section{Docker containers, Pods e services}
install.sh
start.sh
yaml
docker
kubernetes
services

\section{Modifiche al relay necessarie per la versione SaaS}
Il componente relay ha avuto bisogno di numerosi accorgimenti per permettere il suo funzionamento in prospettiva SaaS. Per sua natura, ha bisogno di numerose informazioni a riguardo del server al quale fanno riferimento. Per configurare il relay correttamente è necessario far rinvenire al relay alcuni file contenenti queste informazioni. Questa era una procedura che nella versione on premise veniva fatta a mano. Ora, nella realizzazione del servizio in SaaS, si è implementato un procedimento automatico che fa affidamento sullo storage condiviso fornito dall'NFS.
\paragraph{Relay scaling}
Altra proprietà del relay è la capacità di scalare adeguatamente rispondendo alle necessità. Durante il tipico utilizzo del prodotto è molto comune che il numero dei client o la mole di lavoro richiesta cambino dinamicamente. Superata una certa soglia di workload o un certo numero di client (circa 1000), un singolo relay non è più in grado di far fronte alle richieste, ma ha bisogno che parte dell'onere di lavoro venga presa in carico da una sua copia identica. Questo processo viene chiamato si "scale up". Analogamente possono verificarsi delle situazioni in cui le risorse allocate siano sovradimensionate rispetto al carico di lavoro. Fortunatamente Kubernetes fornisce un comando ad hoc per queste necessità. Questo strumento utilizza dei volumi condivisi di appoggio per fare si che le nuove copie dei relay non si debbano configurare da capo. Il nuovo relay infatti eredita dal primo sia tutte le configurazioni di BigFix e di Docker, ma anche la cache dell'altro relay, in maniera tale da essere subito operativo in pochi secondi

\section{Automazione del Deployment}
Facciamo il punto della situazione cercando di individuare gli elementi che sono stati definiti fino a questo punto. Abbiamo da un lato la possibilità di deployare dei container che svolgano le funzioni di server o di relay perfettamente funzionanti, da un'altro c'è il database DB2 pronto a fornire persistenza a tutti i dati del cliente, da un'altro ancora altri componenti necessari all'ambiente per il corretto funzionamento, come l'NFS. Supponiamo che in un istante non predicibile un nuovo cliente acquisti la licenza ad utilizzare BigFix SaaS e abbia appena compilato la form con tutti i dati necessari. Cosa manca? 
\paragraph{}
Non è certo pensabile che a questo punto ci sia bisogno di un intervento umano per mettere a disposizione del nuovo cliente tutte le risorse necessarie. Ci si aspetta che il servizio sia disponibile nel giro di poche ore e la richiesta può essere avvenuta da qualunque parte del mondo e in qualunque momento della giornata.
\paragraph{}
Ecco quindi che è stato necessario un processo di software automation. Un processo automatico cioè che porti il prodotto ad essere pronto all'utilizzo da parte del nuovo cliente. Questo processo deve essere tollerante a malfunzionamenti e deve poter interagire con tutte le componenti facenti parte del sistema. Deve, in sostanza, comportarsi come una figura umana dedita all'istallazione. 

\subsection{Bash Scripting}
Nel progetto si è fatto largo uso del linguaggio Bash. Dovendo interagire con sistemi UNIX esso è sta to spesso inserito in processi di automazione presenti negli scenari di gestione del sistema.
\paragraph{}
Bash, acronimo che sta per Bourne-Again-Shell, è un'interfaccia a riga di comando pensata per gestire i sistemi operativi UNIX nata alla fine degli anni '80. Come altri strumenti analoghi, oltre alla modalità interattiva, prevede anche la possibilità di creare script, con funzioni, cicli e costrutti tipici, e di eseguirli poi in blocco. Questi script sono contraddistinti dall'estensione .sh e dall'incipit "\#!/bin/bash", il quale indica il percorso della shell che dovrà eseguire lo script, Bash per l'appunto. 
\paragraph{Utilizzo degli script Bash nel progetto}
Gli script Bash sono stati di fondamentale importanza per il progetto. Data la loro versatilità e potenza è stato possibile utilizzarli per molti scopi di configurazione. Sono entrati, ad esempio, in dei flussi Ansible e Jenkins. Questi script venivano mandati tramite scp su opportune macchine macchine e, una volta configurati i permessi, venivano eseguiti per svolgere i più disparati compiti necessari.
\subsection{Jenkins}
\subsection{UrbanCode}
\subsection{Ansible}

\section{Scenario di onboarding di un nuovo cliente}

\section{Scenario di upgrade del servizio}

\section{Automazione del Testing}
\subsection{Functional Test}
\subsubsection{JUnit}
\subsubsection{JUTAA}
\subsection{Security Test}
\subsubsection{AppScan}
\subsubsection{Image Compliance}
\subsection{Performance Test}
\subsection{Penetration Test}
\subsection{Rielaborazione degli output del testing}

\section{Scenario di testing}

\section{Il passaggio all'ambiente di produzione}
kubernetes -> ip pubblico, dns
\subsection{}
code promotion e continuos delivery

